{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d70376",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:40.119012Z",
     "iopub.status.busy": "2024-04-12T13:29:40.118521Z",
     "iopub.status.idle": "2024-04-12T13:29:45.286901Z",
     "shell.execute_reply": "2024-04-12T13:29:45.285393Z"
    },
    "papermill": {
     "duration": 5.180042,
     "end_time": "2024-04-12T13:29:45.290197",
     "exception": false,
     "start_time": "2024-04-12T13:29:40.110155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np\n",
    "import pdb\n",
    "import copy\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    T.manual_seed(seed)\n",
    "    T.cuda.manual_seed(seed)\n",
    "    T.backends.cudnn.deterministic = True\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), keepdims=True)\n",
    "\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa662f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.304649Z",
     "iopub.status.busy": "2024-04-12T13:29:45.303981Z",
     "iopub.status.idle": "2024-04-12T13:29:45.313419Z",
     "shell.execute_reply": "2024-04-12T13:29:45.311905Z"
    },
    "papermill": {
     "duration": 0.019519,
     "end_time": "2024-04-12T13:29:45.315914",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.296395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soft_update(target, source, tau):\n",
    "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
    "\t\ttarget_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
    "\t\ttarget_param.data.copy_(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb797e9",
   "metadata": {
    "papermill": {
     "duration": 0.005062,
     "end_time": "2024-04-12T13:29:45.326342",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.321280",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4715ccbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.341375Z",
     "iopub.status.busy": "2024-04-12T13:29:45.338752Z",
     "iopub.status.idle": "2024-04-12T13:29:45.353932Z",
     "shell.execute_reply": "2024-04-12T13:29:45.352528Z"
    },
    "papermill": {
     "duration": 0.025052,
     "end_time": "2024-04-12T13:29:45.356679",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.331627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self,input_shape, n_actions,max_size=int(1e6)):\n",
    "        self.memory_size = max_size\n",
    "        self.memory_counter = 0\n",
    "        self.state = np.zeros((self.memory_size, input_shape))\n",
    "        self.state_ = np.zeros((self.memory_size, input_shape))\n",
    "        self.action = np.zeros((self.memory_size, n_actions))\n",
    "        self.reward = np.zeros(self.memory_size)\n",
    "        self.done = np.zeros(self.memory_size)\n",
    "\n",
    "    def add(self, state, action, reward, state_, done):\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.state[index] = state\n",
    "        self.state_[index] = state_\n",
    "        self.action[index] = action\n",
    "        self.reward[index] = reward\n",
    "        self.done[index] = done\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        max_memory = min(self.memory_counter, self.memory_size)\n",
    "        batch = np.random.choice(max_memory, batch_size)\n",
    "        state = self.state[batch]\n",
    "        action= self.action[batch]\n",
    "        reward = self.reward[batch]\n",
    "        state_ = self.state_[batch]\n",
    "        done = self.done[batch]\n",
    "        return state, action, reward, state_, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c105a9f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.369330Z",
     "iopub.status.busy": "2024-04-12T13:29:45.368934Z",
     "iopub.status.idle": "2024-04-12T13:29:45.385002Z",
     "shell.execute_reply": "2024-04-12T13:29:45.383354Z"
    },
    "papermill": {
     "duration": 0.026204,
     "end_time": "2024-04-12T13:29:45.388252",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.362048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "\tdef __init__(self, state_dim, action_dim, max_action):\n",
    "\t\tsuper(Actor, self).__init__()\n",
    "\t\tself.l1 = nn.Linear(state_dim, 256)\n",
    "\t\tself.l2 = nn.Linear(256, 256)\n",
    "\t\tself.l3 = nn.Linear(256, action_dim)\n",
    "\t\tself.max_action = max_action\n",
    "\tdef forward(self, state):\n",
    "\t\ta = F.relu(self.l1(state))\n",
    "\t\ta = F.relu(self.l2(a))\n",
    "\t\treturn self.max_action * torch.sigmoid(self.l3(a))\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\tdef __init__(self, state_dim, action_dim):\n",
    "\t\tsuper(Critic, self).__init__()\n",
    "\t\t# Q1 architecture\n",
    "\t\tself.l1 = nn.Linear(state_dim + action_dim, 256)\n",
    "\t\tself.l2 = nn.Linear(256, 256)\n",
    "\t\tself.l3 = nn.Linear(256, 1)\n",
    "\t\t# Q2 architecture\n",
    "\t\tself.l4 = nn.Linear(state_dim + action_dim, 256)\n",
    "\t\tself.l5 = nn.Linear(256, 256)\n",
    "\t\tself.l6 = nn.Linear(256, 1)\n",
    "\tdef forward(self, state, action):\n",
    "\t\tsa = torch.cat([state, action], 1)\n",
    "\t\tq1 = F.relu(self.l1(sa))\n",
    "\t\tq1 = F.relu(self.l2(q1))\n",
    "\t\tq1 = self.l3(q1)\n",
    "\t\tq2 = F.relu(self.l4(sa))\n",
    "\t\tq2 = F.relu(self.l5(q2))\n",
    "\t\tq2 = self.l6(q2)\n",
    "\t\treturn q1, q2\n",
    "\tdef Q1(self, state, action):\n",
    "\t\tsa = torch.cat([state, action], 1)\n",
    "\t\tq1 = F.relu(self.l1(sa))\n",
    "\t\tq1 = F.relu(self.l2(q1))\n",
    "\t\tq1 = self.l3(q1)\n",
    "\t\treturn q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f31c6b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.401810Z",
     "iopub.status.busy": "2024-04-12T13:29:45.401399Z",
     "iopub.status.idle": "2024-04-12T13:29:45.427576Z",
     "shell.execute_reply": "2024-04-12T13:29:45.426320Z"
    },
    "papermill": {
     "duration": 0.035992,
     "end_time": "2024-04-12T13:29:45.430071",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.394079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TD3(object):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tstate_dim,\n",
    "\t\taction_dim,\n",
    "\t\tmax_action,\n",
    "\t\tdiscount=0.99,\n",
    "\t\ttau=0.005,\n",
    "\t\tpolicy_noise=0.2,\n",
    "\t\tnoise_clip=0.5,\n",
    "\t\tpolicy_freq=2\n",
    "\t):\n",
    "\n",
    "\t\tself.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "\t\tself.actor_target = copy.deepcopy(self.actor)\n",
    "\t\tself.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=3e-4)\n",
    "\t\tself.critic = Critic(state_dim, action_dim).to(device)\n",
    "\t\tself.critic_target = copy.deepcopy(self.critic)\n",
    "\t\tself.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=3e-4)\n",
    "\t\tself.max_action = max_action\n",
    "\t\tself.discount = discount\n",
    "\t\tself.tau = tau\n",
    "\t\tself.policy_noise = policy_noise\n",
    "\t\tself.noise_clip = noise_clip\n",
    "\t\tself.policy_freq = policy_freq\n",
    "\t\tself.total_it = 0\n",
    "\n",
    "\tdef select_action(self, state):\n",
    "\t\tstate = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
    "\t\treturn self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "\tdef train(self, replay_buffer, batch_size=100):\n",
    "\t\tif replay_buffer.memory_size<batch_size:\n",
    "\t\t\treturn\n",
    "\t\tself.total_it += 1\n",
    "\t\tstate, action, reward,next_state, not_done = replay_buffer.sample(batch_size)\n",
    "\t\treward = T.tensor(reward, dtype=T.float)\n",
    "\t\tnot_done = T.tensor(not_done,dtype=T.float)\n",
    "\t\tnext_state = T.tensor(next_state, dtype=T.float)\n",
    "\t\tstate = T.tensor(state, dtype=T.float)\n",
    "\t\taction = T.tensor(action, dtype=T.float)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tnoise = (\n",
    "\t\t\t\ttorch.randn_like(action) * self.policy_noise\n",
    "\t\t\t).clamp(-self.noise_clip, self.noise_clip)\n",
    "\n",
    "\t\t\tnext_action = (\n",
    "\t\t\t\tself.actor_target(next_state) + noise\n",
    "\t\t\t).clamp(-self.max_action, self.max_action)\n",
    "\t\t\ttarget_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
    "\t\t\ttarget_Q = torch.squeeze(torch.min(target_Q1, target_Q2))\n",
    "\t\t\ttarget_Q = reward + not_done * self.discount * target_Q\n",
    "\t\tcurrent_Q1, current_Q2 = self.critic(state, action)\n",
    "\t\tcritic_loss = F.mse_loss(torch.squeeze(current_Q1), target_Q) + F.mse_loss(torch.squeeze(current_Q2), target_Q)\n",
    "\t\tself.critic_optimizer.zero_grad()\n",
    "\t\tcritic_loss.backward()\n",
    "\t\tself.critic_optimizer.step()\n",
    "\t\tif self.total_it % self.policy_freq == 0:\n",
    "\t\t\tactor_loss = -self.critic.Q1(state, self.actor(state)).mean()\n",
    "\t\t\tself.actor_optimizer.zero_grad()\n",
    "\t\t\tactor_loss.backward()\n",
    "\t\t\tself.actor_optimizer.step()\n",
    "\t\t\tfor param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "\t\t\t\ttarget_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\t\t\tfor param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "\t\t\t\ttarget_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "\tdef save(self, filename):\n",
    "\t\ttorch.save(self.critic.state_dict(), filename + \"_critic\")\n",
    "\t\ttorch.save(self.critic_optimizer.state_dict(), filename + \"_critic_optimizer\")\n",
    "\t\ttorch.save(self.actor.state_dict(), filename + \"_actor\")\n",
    "\t\ttorch.save(self.actor_optimizer.state_dict(), filename + \"_actor_optimizer\")\n",
    "\n",
    "\tdef load(self, filename):\n",
    "\t\tself.critic.load_state_dict(torch.load(filename + \"_critic\"))\n",
    "\t\tself.critic_optimizer.load_state_dict(torch.load(filename + \"_critic_optimizer\"))\n",
    "\t\tself.critic_target = copy.deepcopy(self.critic)\n",
    "\t\tself.actor.load_state_dict(torch.load(filename + \"_actor\"))\n",
    "\t\tself.actor_optimizer.load_state_dict(torch.load(filename + \"_actor_optimizer\"))\n",
    "\t\tself.actor_target = copy.deepcopy(self.actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "624c2eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.442887Z",
     "iopub.status.busy": "2024-04-12T13:29:45.442458Z",
     "iopub.status.idle": "2024-04-12T13:29:45.452842Z",
     "shell.execute_reply": "2024-04-12T13:29:45.451517Z"
    },
    "papermill": {
     "duration": 0.019542,
     "end_time": "2024-04-12T13:29:45.455181",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.435639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [2, 4], 2: [1, 2]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_dependencies={0:[2,4],\n",
    "    2:[1,2]}\n",
    "task_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c0c854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.468937Z",
     "iopub.status.busy": "2024-04-12T13:29:45.467805Z",
     "iopub.status.idle": "2024-04-12T13:29:45.485410Z",
     "shell.execute_reply": "2024-04-12T13:29:45.484103Z"
    },
    "papermill": {
     "duration": 0.027277,
     "end_time": "2024-04-12T13:29:45.487862",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.460585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([119.4708202 , 119.4708202 , 119.4708202 , 119.4708202 ,\n",
       "          5.94810189,  16.16861729]),\n",
       " array([ 19.86715367,  19.86715367, 146.799513  , 146.799513  ,\n",
       "        146.799513  ,  19.86715367]),\n",
       " array([ 14.32206915,  14.32206915, 287.66644869, 105.82657239,\n",
       "         38.93142031,  38.93142031]),\n",
       " array([140.72607591,  51.77023016, 140.72607591,   7.00633876,\n",
       "         19.04520334, 140.72607591]),\n",
       " array([  3.77980841, 206.37054669, 206.37054669,   3.77980841,\n",
       "         75.91948139,   3.77980841])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_requirements=[(softmax(np.random.randint(0,5,size=[6])) * 10 * 50) for i in range(5)]\n",
    "resource_requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c195be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.501680Z",
     "iopub.status.busy": "2024-04-12T13:29:45.501165Z",
     "iopub.status.idle": "2024-04-12T13:29:45.514190Z",
     "shell.execute_reply": "2024-04-12T13:29:45.512771Z"
    },
    "papermill": {
     "duration": 0.023684,
     "end_time": "2024-04-12T13:29:45.517244",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.493560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resource_Manager:\n",
    "    def __init__(self,action_dims=6,resource_amount=10,max_steps=2000,):\n",
    "        self.resource_amount=np.expand_dims(np.array(resource_amount),axis=0)\n",
    "        self.action_dims = (1,action_dims)\n",
    "        self.space_dims=(1,self.action_dims[1]+1)\n",
    "        self.max_steps=max_steps\n",
    "        \n",
    "    def reset(self):\n",
    "        self.steps_so_far=0\n",
    "        self.resource_requirements=softmax(np.random.randint(0,4,size=[self.action_dims[1]])) * self.resource_amount * 50\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        self.resource_amount=np.expand_dims(np.random.randint(1,20),axis=0)\n",
    "        return np.concatenate([self.resource_amount,self.resource_requirements])\n",
    "    \n",
    "    def step(self, action):\n",
    "        action=softmax(action) * self.resource_amount\n",
    "        self.resource_requirements-= action    \n",
    "        self.resource_requirements=np.clip(self.resource_requirements,0,max(max(self.resource_requirements),0))\n",
    "        \n",
    "        self.steps_so_far+=1\n",
    "        if np.count_nonzero(self.resource_requirements)<1:\n",
    "            return self.get_state(),100,True,False\n",
    "        return self.get_state(),-1,False,self.steps_so_far>=self.max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c99e58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.531861Z",
     "iopub.status.busy": "2024-04-12T13:29:45.531376Z",
     "iopub.status.idle": "2024-04-12T13:29:45.545773Z",
     "shell.execute_reply": "2024-04-12T13:29:45.544297Z"
    },
    "papermill": {
     "duration": 0.02547,
     "end_time": "2024-04-12T13:29:45.548817",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.523347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set_seed(97)\n",
    "def get_trained_policy():\n",
    "    env =Resource_Manager()\n",
    "\n",
    "    state_dim = env.space_dims[1]\n",
    "    action_dim = env.action_dims[1]\n",
    "    max_action = float(1)\n",
    "\n",
    "    kwargs = {\"state_dim\": state_dim,\"action_dim\": action_dim,\"max_action\": max_action,\"discount\": 0.99,\"tau\": 0.005,}\n",
    "    kwargs[\"policy_noise\"] = 0.2 * max_action\n",
    "    kwargs[\"noise_clip\"] = 0.5 * max_action\n",
    "    kwargs[\"policy_freq\"] = 2\n",
    "    policy = TD3(**kwargs)\n",
    "    \n",
    "    replay_buffer = ReplayBuffer(state_dim, action_dim)\n",
    "\n",
    "    time_step=0\n",
    "    start_timesteps=10000\n",
    "    rewards=[]\n",
    "\n",
    "    for episode in range(2000):\n",
    "        episode_reward=0\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        truncuated = False\n",
    "        while (not done) and (not truncuated):\n",
    "            action = (policy.select_action(state)+ np.random.normal(0, max_action * 0.1, size=action_dim)).clip(0, max_action)\n",
    "            next_state, reward, done,truncuated = env.step(action)\n",
    "            replay_buffer.add(state, action, reward,next_state, int(not(done)))\n",
    "            if time_step > start_timesteps:\n",
    "                policy.train(replay_buffer)\n",
    "            state = next_state\n",
    "            time_step+=1\n",
    "            episode_reward+=reward\n",
    "        rewards.append(episode_reward)\n",
    "        if (episode%50)==0:\n",
    "            print(f\"episode:{episode} reward:{episode_reward} last 50 ep AVG:{sum(rewards[-100:])/100}\")\n",
    "    return copy.deepcopy(policy.actor),copy.deepcopy(TD3(**kwargs).actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f52387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:29:45.563415Z",
     "iopub.status.busy": "2024-04-12T13:29:45.562953Z",
     "iopub.status.idle": "2024-04-12T13:59:22.368507Z",
     "shell.execute_reply": "2024-04-12T13:59:22.366475Z"
    },
    "papermill": {
     "duration": 1776.825355,
     "end_time": "2024-04-12T13:59:22.380315",
     "exception": false,
     "start_time": "2024-04-12T13:29:45.554960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:0 reward:-131 last 50 ep AVG:-1.31\n",
      "episode:50 reward:79 last 50 ep AVG:-17.3\n",
      "episode:100 reward:39 last 50 ep AVG:-35.98\n",
      "episode:150 reward:-123 last 50 ep AVG:-44.49\n",
      "episode:200 reward:81 last 50 ep AVG:-40.1\n",
      "episode:250 reward:5 last 50 ep AVG:-37.29\n",
      "episode:300 reward:-94 last 50 ep AVG:-42.13\n",
      "episode:350 reward:88 last 50 ep AVG:-44.8\n",
      "episode:400 reward:-88 last 50 ep AVG:-37.85\n",
      "episode:450 reward:-34 last 50 ep AVG:-21.47\n",
      "episode:500 reward:-127 last 50 ep AVG:-12.84\n",
      "episode:550 reward:66 last 50 ep AVG:-3.31\n",
      "episode:600 reward:-72 last 50 ep AVG:-0.94\n",
      "episode:650 reward:26 last 50 ep AVG:-4.56\n",
      "episode:700 reward:6 last 50 ep AVG:2.82\n",
      "episode:750 reward:28 last 50 ep AVG:9.63\n",
      "episode:800 reward:31 last 50 ep AVG:7.93\n",
      "episode:850 reward:6 last 50 ep AVG:6.8\n",
      "episode:900 reward:16 last 50 ep AVG:14.1\n",
      "episode:950 reward:-2 last 50 ep AVG:16.68\n",
      "episode:1000 reward:51 last 50 ep AVG:18.38\n",
      "episode:1050 reward:-8 last 50 ep AVG:16.76\n",
      "episode:1100 reward:-18 last 50 ep AVG:14.97\n",
      "episode:1150 reward:3 last 50 ep AVG:22.61\n",
      "episode:1200 reward:67 last 50 ep AVG:21.68\n",
      "episode:1250 reward:87 last 50 ep AVG:21.11\n",
      "episode:1300 reward:14 last 50 ep AVG:20.31\n",
      "episode:1350 reward:-19 last 50 ep AVG:18.95\n",
      "episode:1400 reward:-4 last 50 ep AVG:25.9\n",
      "episode:1450 reward:94 last 50 ep AVG:20.63\n",
      "episode:1500 reward:58 last 50 ep AVG:18.78\n",
      "episode:1550 reward:81 last 50 ep AVG:24.55\n",
      "episode:1600 reward:-53 last 50 ep AVG:22.73\n",
      "episode:1650 reward:90 last 50 ep AVG:31.71\n",
      "episode:1700 reward:26 last 50 ep AVG:32.51\n",
      "episode:1750 reward:59 last 50 ep AVG:29.67\n",
      "episode:1800 reward:19 last 50 ep AVG:30.79\n",
      "episode:1850 reward:45 last 50 ep AVG:28.15\n",
      "episode:1900 reward:30 last 50 ep AVG:26.33\n",
      "episode:1950 reward:-33 last 50 ep AVG:23.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Actor(\n",
       "   (l1): Linear(in_features=7, out_features=256, bias=True)\n",
       "   (l2): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (l3): Linear(in_features=256, out_features=6, bias=True)\n",
       " ),\n",
       " Actor(\n",
       "   (l1): Linear(in_features=7, out_features=256, bias=True)\n",
       "   (l2): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (l3): Linear(in_features=256, out_features=6, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocator,random_allocator=get_trained_policy()\n",
    "allocator,random_allocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb77f349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:59:22.402517Z",
     "iopub.status.busy": "2024-04-12T13:59:22.401411Z",
     "iopub.status.idle": "2024-04-12T13:59:22.421595Z",
     "shell.execute_reply": "2024-04-12T13:59:22.420357Z"
    },
    "papermill": {
     "duration": 0.034869,
     "end_time": "2024-04-12T13:59:22.424636",
     "exception": false,
     "start_time": "2024-04-12T13:59:22.389767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resouce_Allocator:\n",
    "    def __init__(self,allocator,num_tasks,num_resources,task_dependencies=None,resource_requirements=None):\n",
    "        self.task_dependencies=task_dependencies\n",
    "        self.num_tasks=num_tasks\n",
    "        self.num_resources=num_resources\n",
    "        self.allocator=allocator\n",
    "        self.resources=resource_requirements\n",
    "        self.steps=0\n",
    "        self.done=np.array([[False for j in range(num_tasks)] for i in range(num_resources)])\n",
    "        self.terminal_state=False\n",
    "    def alloc(self,available_amount,resourcces):\n",
    "        state = torch.FloatTensor(np.concatenate([available_amount,resourcces]).reshape(1, -1)).to(device)\n",
    "        return softmax(self.allocator(state).cpu().data.numpy().flatten()) * available_amount\n",
    "        \n",
    "    def solve(self):\n",
    "        while not self.terminal_state: \n",
    "            available_resource=[np.expand_dims(np.array(random.randint(1,5)),axis=0) for i in range(self.num_resources)]\n",
    "            self.steps+=1\n",
    "            for index,done in zip(range(self.num_resources),self.done):\n",
    "                if done.all(where=False):\n",
    "                    resource=copy.deepcopy(self.resources[index])\n",
    "                    for t_key in self.task_dependencies.keys():\n",
    "                        for r_key in self.task_dependencies[t_key].keys():\n",
    "                            if r_key == index and (not self.done[self.task_dependencies[t_key][r_key]][t_key]):                                \n",
    "                                resource[r_key] = 0.0\n",
    "                    change=self.alloc(available_resource[index],resource)\n",
    "                    change[resource==0.0] = 0\n",
    "                    self.resources[index]-= change\n",
    "                    self.resources[index] = np.clip(self.resources[index],0,max(max(self.resources[index]),0))\n",
    "            self.check_to_do_list()\n",
    "        return self.steps\n",
    "    def check_to_do_list(self):\n",
    "        for recources,done in zip(self.resources,self.done):\n",
    "            indexes=np.where(recources==0)\n",
    "            for index in indexes:\n",
    "                done[index]=True \n",
    "        if sum(sum(i) for i in self.resources)<=0:\n",
    "            self.terminal_state=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2722576c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T13:59:22.446443Z",
     "iopub.status.busy": "2024-04-12T13:59:22.445971Z",
     "iopub.status.idle": "2024-04-12T13:59:39.365041Z",
     "shell.execute_reply": "2024-04-12T13:59:39.363769Z"
    },
    "papermill": {
     "duration": 16.933383,
     "end_time": "2024-04-12T13:59:39.367927",
     "exception": false,
     "start_time": "2024-04-12T13:59:22.434544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([692.18288001, 692.18288001,  12.67777168,  93.67676612,\n",
      "       254.63985109, 254.63985109]), array([211.94155762, 576.11688477, 211.94155762, 211.94155762,\n",
      "       211.94155762, 576.11688477]), array([ 93.67676612, 254.63985109, 692.18288001, 692.18288001,\n",
      "        12.67777168, 254.63985109]), array([1014.88413735,  373.3550093 ,  137.34963218,   50.52810593,\n",
      "         50.52810593,  373.3550093 ]), array([ 385.67336034,  141.88130028,  385.67336034, 1048.36888713,\n",
      "         19.20154596,   19.20154596])] \n",
      "\n",
      "\n",
      "\n",
      "1334\n",
      "1530\n",
      "2840\n",
      "4313\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_resources=5        \n",
    "num_tasks=6\n",
    "\n",
    "resource_requirements=[(softmax(np.random.randint(0,5,size=[num_tasks])) * 10 * 200) for i in range(num_resources)]\n",
    "print(resource_requirements,\"\\n\\n\\n\") \n",
    "\n",
    "order1={0:{2:1}}\n",
    "order2={0:{1:0,3:2,4:3},1:{1:0,3:2,4:3},2:{1:0,3:2,4:3},3:{2:1,3:2,4:3},4:{2:1,3:2,4:3},5:{2:1,3:2,4:3}}\n",
    "\n",
    "r1=Resouce_Allocator(allocator=allocator,num_tasks=num_tasks,num_resources=num_resources,task_dependencies=order1,resource_requirements= copy.deepcopy(resource_requirements))\n",
    "print(r1.solve())\n",
    "\n",
    "\n",
    "r2=Resouce_Allocator(allocator=allocator,num_tasks=num_tasks,num_resources=num_resources,task_dependencies=order2,resource_requirements= copy.deepcopy(resource_requirements))\n",
    "print(r2.solve())\n",
    "\n",
    "\n",
    "r3=Resouce_Allocator(allocator=random_allocator,num_tasks=num_tasks,num_resources=num_resources,task_dependencies=order1,resource_requirements= copy.deepcopy(resource_requirements))\n",
    "print(r3.solve())\n",
    "\n",
    "\n",
    "r4=Resouce_Allocator(allocator=random_allocator,num_tasks=num_tasks,num_resources=num_resources,task_dependencies=order2,resource_requirements= copy.deepcopy(resource_requirements))\n",
    "print(r4.solve())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1804.594571,
   "end_time": "2024-04-12T13:59:41.112752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-12T13:29:36.518181",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
